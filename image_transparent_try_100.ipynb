{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPY6McGTuhDXrw3tLWTKEY2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saktheeswaranswan/random-math-addition-data-for-rnn-generator/blob/main/image_transparent_try_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zIVBQYu3g_a-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_background(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    foreground = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "    background = np.full(img.shape, 255, dtype=np.uint8)\n",
        "    background = cv2.bitwise_and(background, background, mask=cv2.bitwise_not(mask))\n",
        "\n",
        "    transparent = cv2.addWeighted(background, 0.5, foreground, 0.5, 0)\n",
        "    transparent = cv2.cvtColor(transparent, cv2.COLOR_BGR2RGBA)\n",
        "    _, alpha = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY)\n",
        "    b, g, r, a = cv2.split(transparent)\n",
        "    rgba = [b, g, r, alpha]\n",
        "    transparent = cv2.merge(rgba, 4)\n",
        "\n",
        "    return transparent\n",
        "\n",
        "def process_images(image_folder):\n",
        "    for i, filename in enumerate(os.listdir(image_folder)):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(image_folder, filename)\n",
        "            transparent = remove_background(image_path)\n",
        "            cv2.imwrite(\"transparent_\" + str(i) + \".png\", transparent, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
        "\n",
        "process_images(\"/content/images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def remove_background(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    pixels = img.reshape(-1, 3).astype(np.float32)\n",
        "\n",
        "    k = 2\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "    background_pixels = pixels[labels.flatten() == 0]\n",
        "    mean_background = np.mean(background_pixels, axis=0).astype(np.uint8)\n",
        "\n",
        "    mask = np.zeros(img.shape[:2], np.uint8)\n",
        "    mask[np.all(np.abs(img - mean_background) < 15, axis=-1)] = 255\n",
        "    mask = cv2.medianBlur(mask, 7)\n",
        "\n",
        "    foreground = cv2.bitwise_and(img, img, mask=mask)\n",
        "    background = np.full(img.shape, mean_background, dtype=np.uint8)\n",
        "    background = cv2.bitwise_and(background, background, mask=cv2.bitwise_not(mask))\n",
        "\n",
        "    transparent = cv2.addWeighted(background, 0.5, foreground, 0.5, 0)\n",
        "    transparent = cv2.cvtColor(transparent, cv2.COLOR_RGB2RGBA)\n",
        "    _, alpha = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY)\n",
        "    b, g, r, a = cv2.split(transparent)\n",
        "    rgba = [b, g, r, alpha]\n",
        "    transparent = cv2.merge(rgba, 4)\n",
        "\n",
        "    return transparent\n",
        "\n",
        "def process_images(image_folder):\n",
        "    for i, filename in enumerate(os.listdir(image_folder)):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(image_folder, filename)\n",
        "            transparent = remove_background(image_path)\n",
        "            cv2.imwrite(os.path.join(image_folder, \"transparent_\" + str(i) + \".png\"), transparent, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
        "\n",
        "process_images(\"/content/images/\")\n"
      ],
      "metadata": {
        "id": "WiwH1XoljdPf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_background(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    pixels = np.float32(image.reshape(-1, 3))\n",
        "\n",
        "    k = 2\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 200, .1)\n",
        "    _, labels, (centers) = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "    center = np.uint8(centers)\n",
        "    labels = labels.flatten()\n",
        "    background_label = 0\n",
        "    background_pixels = pixels[labels == background_label]\n",
        "    mean = np.mean(background_pixels, axis=0)\n",
        "    background_color = np.uint8(mean)\n",
        "\n",
        "    mask = labels != background_label\n",
        "    image = image.reshape(-1, 3)\n",
        "    image = np.uint8(image)\n",
        "    image[mask] = image[mask]\n",
        "    image = image.reshape(image.shape[0], image.shape[1], -1)\n",
        "\n",
        "    transparent = np.zeros((image.shape[0], image.shape[1], 4), dtype=np.uint8)\n",
        "    transparent[:, :, :3] = image\n",
        "    mask = mask.reshape((mask.shape[0], 1))\n",
        "    transparent[:, :, 3] = mask.astype(int) * 255\n",
        "\n",
        "\n",
        "    return transparent\n",
        "\n",
        "image_folder = \"/content/images\"\n",
        "output_folder = \"/content/output\"\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "for i, filename in enumerate(os.listdir(image_folder)):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
        "        image_path = os.path.join(image_folder, filename)\n",
        "        transparent = remove_background(image_path)\n",
        "        output_path = os.path.join(output_folder, \"transparent_\" + str(i) + \".png\")\n",
        "        cv2.imwrite(output_path, transparent)\n"
      ],
      "metadata": {
        "id": "T6DjTib4l64a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_background(img_path):\n",
        "    # Load the image\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    # Define a rectangle that covers the object in focus\n",
        "    rect = (50, 50, img.shape[1]-100, img.shape[0]-100)\n",
        "\n",
        "    # Define the mask for the GrabCut algorithm\n",
        "    mask = np.zeros(img.shape[:2], np.uint8)\n",
        "    bg_model = np.zeros((1, 65), np.float64)\n",
        "    fg_model = np.zeros((1, 65), np.float64)\n",
        "\n",
        "    # Run the GrabCut algorithm to segment the image\n",
        "    cv2.grabCut(img, mask, rect, bg_model, fg_model, 5, cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "    # Create a binary mask with the segmentation results\n",
        "    mask = np.where((mask==2)|(mask==0), 0, 1).astype('uint8')\n",
        "    img = img * mask[:,:,np.newaxis]\n",
        "\n",
        "    # Save the output as a transparent PNG\n",
        "    alpha = np.ones(img.shape[:2], dtype=np.uint8) * 255\n",
        "    transparent = np.dstack((img, alpha))\n",
        "    cv2.imwrite(f\"{os.path.splitext(img_path)[0]}_transparent.png\", transparent)\n",
        "\n",
        "# Example usage:\n",
        "remove_background(\"/content/images/dgsdgsd.jpg\")\n",
        "remove_background(\"/content/images/images.jpeg\")\n"
      ],
      "metadata": {
        "id": "JnEJtLy4nstD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Read images from the directory\n",
        "images_path = \"/content/images\"\n",
        "images = [f for f in os.listdir(images_path) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "for image_name in images:\n",
        "    image_path = os.path.join(images_path, image_name)\n",
        "    image = cv2.imread(image_path)\n",
        "    h, w, c = image.shape\n",
        "\n",
        "    # Convert image to LAB color space and separate channels\n",
        "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "\n",
        "    # Apply k-means clustering to the L channel\n",
        "    k = 5\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "    pixels = l.reshape(-1, 1)\n",
        "    _, labels, (centers) = cv2.kmeans(pixels.astype(np.float32), k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "    # Create a binary mask based on the k-means result\n",
        "    mask = np.zeros(l.shape[:2], dtype=np.uint8)\n",
        "    for i in range(k):\n",
        "        if centers[i] > 128:\n",
        "            labels = labels.reshape(mask.shape)\n",
        "            mask[labels == i] = 255\n",
        "    \n",
        "    # Remove the out-of-focus parts using the binary mask\n",
        "    result = cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "    # Create a transparent background\n",
        "    transparent = np.zeros((h, w, 4), dtype=np.uint8)\n",
        "    transparent[:, :, :3] = result\n",
        "    transparent[:, :, 3] = mask.astype(int) * 255\n",
        "\n",
        "    # Save the image as a transparent PNG\n",
        "    save_path = os.path.join(images_path, image_name.split(\".\")[0] + \"_result.png\")\n",
        "    cv2.imwrite(save_path, transparent)\n"
      ],
      "metadata": {
        "id": "LCUF6QOFpldI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "path = \"/content/images/\"\n",
        "\n",
        "for filename in os.listdir(path):\n",
        "    image = cv2.imread(os.path.join(path, filename))\n",
        "    if image is None:\n",
        "    print(\"Error: Image not loaded.\")\n",
        "else:\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    ret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    mask = np.dstack([mask, mask, mask]) / 255\n",
        "    h, w, c = image.shape\n",
        "    mask, bg = np.zeros((h, w), np.uint8), np.zeros((h, w), np.uint8)\n",
        "    rect = (1, 1, w-2, h-2)\n",
        "    cv2.grabCut(image, mask, rect, bg, fg, 5, cv2.GC_INIT_WITH_RECT)\n",
        "    mask = np.where((mask == 2)|(mask == 0), 0, 1).astype('uint8')\n",
        "    image = image * mask[:, :, np.newaxis]\n",
        "    bg = np.ones_like(image, np.uint8) * 255\n",
        "    final = cv2.addWeighted(image, 0.7, bg, 0.3, 0)\n",
        "    cv2.imwrite(os.path.join(path, \"result_\" + filename), final)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "c7dCfI3rp5sJ",
        "outputId": "1fb102e0-e584-429e-8ba6-35dd2751a6c4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-394186bd8dea>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    print(\"Error: Image not loaded.\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def remove_background(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Perform Otsu thresholding to create a binary mask\n",
        "    ret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Define the mask for the GrabCut algorithm\n",
        "    mask = np.where((mask == 0), 0, 1).astype('uint8')\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "    # Perform GrabCut to remove the out-of-focus parts\n",
        "    rect = (0, 0, image.shape[1], image.shape[0])\n",
        "    cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
        "\n",
        "    # Create a transparent image\n",
        "    transparent = np.zeros_like(image, dtype=np.uint8)\n",
        "    transparent[:, :, :3] = image\n",
        "    transparent[:, :, 3] = mask.astype(int) * 255\n",
        "\n",
        "    return transparent\n",
        "\n",
        "# Define the path to the images\n",
        "image_folder = '/content/images/'\n",
        "\n",
        "# Loop through all the images in the folder\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith('.jpg'):\n",
        "        # Load the image\n",
        "        image = cv2.imread(os.path.join(image_folder, filename))\n",
        "\n",
        "        # Remove the out-of-focus parts and create a transparent image\n",
        "        transparent = remove_background(image)\n",
        "\n",
        "        # Save the transparent image as a PNG file\n",
        "        cv2.imwrite(os.path.join(image_folder, 'transparent_' + filename.replace('.jpg', '.png')), transparent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "f3vpiGYorg4h",
        "outputId": "c7a80dad-9afe-4171-e078-d87da4188ddf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-492983278f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Remove the out-of-focus parts and create a transparent image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtransparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Save the transparent image as a PNG file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-492983278f3e>\u001b[0m in \u001b[0;36mremove_background\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtransparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtransparent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtransparent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 2 with size 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "path = \"/content/images/\"\n",
        "\n",
        "for filename in os.listdir(path):\n",
        "    image = cv2.imread(os.path.join(path,filename))\n",
        "    \n",
        "    if image is None:\n",
        "        print(\"Error: Image not loaded.\")\n",
        "    else:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Perform Otsu thresholding\n",
        "        thresh, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "        \n",
        "        # Define the mask for the GrabCut algorithm\n",
        "        mask = np.where((mask==0), 0, 1).astype('uint8')\n",
        "        bgModel = np.zeros((1,65),np.float64)\n",
        "        fgModel = np.zeros((1,65),np.float64)\n",
        "        \n",
        "        # Perform GrabCut\n",
        "        x,y,w,h = cv2.boundingRect(mask)\n",
        "        rect = (x,y,w,h)\n",
        "        bgdModel = np.zeros((1,65),np.float64)\n",
        "        fgdModel = np.zeros((1,65),np.float64)\n",
        "        cv2.grabCut(image,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
        "        mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "        \n",
        "        # Create a transparent image\n",
        "        transparent = np.dstack((image, np.ones_like(mask)*255))\n",
        "        transparent[:,:,3] = mask*255\n",
        "        \n",
        "        # Save the result\n",
        "        cv2.imwrite(os.path.join(path, \"result_\" + filename), transparent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "LkmwEs-6sLO_",
        "outputId": "bf03f0cf-c9a2-4761-e0be-0086d1bc63cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Image not loaded.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9f64a2ade88c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbgdModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mfgdModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrabCut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbgdModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfgdModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGC_INIT_WITH_RECT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define the path to the images\n",
        "path = \"/content/images/\"\n",
        "\n",
        "for filename in os.listdir(path):\n",
        "    # Load the image\n",
        "    image = cv2.imread(path + filename)\n",
        "\n",
        "    # Check if the image was loaded successfully\n",
        "    if image is None:\n",
        "        print(\"Error: Image not loaded.\")\n",
        "        continue\n",
        "    else:\n",
        "        # Convert the image to grayscale\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Perform Otsu thresholding\n",
        "        ret,threshold = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "        # Define the mask for the GrabCut algorithm\n",
        "        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "        bgdModel = np.zeros((1,65),np.float64)\n",
        "        fgdModel = np.zeros((1,65),np.float64)\n",
        "        rect = (0,0,image.shape[1]-1,image.shape[0]-1)\n",
        "\n",
        "        # Perform GrabCut segmentation\n",
        "        cv2.grabCut(image,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_MASK)\n",
        "\n",
        "        # Create the binary mask\n",
        "        mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "\n",
        "        # Apply the binary mask to the image\n",
        "        transparent = cv2.cvtColor(image, cv2.COLOR_BGR2RGBA)\n",
        "        transparent[:, :, 3] = mask.astype(int) * 255\n",
        "\n",
        "        # Save the output\n",
        "        cv2.imwrite(path + \"output_\" + filename, transparent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "LUPJYt2rtDBk",
        "outputId": "460f8f39-118e-4cd8-9fa7-c96c63f92749"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Image not loaded.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4c370c8862fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Perform GrabCut segmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrabCut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbgdModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfgdModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGC_INIT_WITH_MASK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Create the binary mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def get_transparent_mask(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    ret, threshold = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Define the mask for the GrabCut algorithm\n",
        "    mask = np.zeros(image.shape[:2], np.uint8)\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "    rect = (0, 0, image.shape[1] - 1, image.shape[0] - 1)\n",
        "\n",
        "    # Perform GrabCut\n",
        "    cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
        "\n",
        "    # Remove the out-of-focus parts using the binary mask\n",
        "    mask = np.where((mask == cv2.GC_BGD) | (mask == cv2.GC_PR_BGD), 0, 1).astype('uint8')\n",
        "    return mask\n",
        "\n",
        "def remove_background(image):\n",
        "    mask = get_transparent_mask(image)\n",
        "    transparent = np.zeros_like(image)\n",
        "    transparent[:, :, :3] = image[:, :, :3]\n",
        "    transparent[:, :, 3] = mask.astype(int) * 255\n",
        "    return transparent\n",
        "\n",
        "path = '/content/images'\n",
        "images = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
        "\n",
        "for image_name in images:\n",
        "    image_path = os.path.join(path, image_name)\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Error: Image {image_path} not loaded.\")\n",
        "        continue\n",
        "    transparent = remove_background(image)\n",
        "    cv2.imwrite(f\"transparent_{image_name}\", transparent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "NnQ1st8Ptgu9",
        "outputId": "5837ad0a-0509-474e-e4e7-22e4b90efd70"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3dab1da789fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error: Image {image_path} not loaded.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtransparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"transparent_{image_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-3dab1da789fc>\u001b[0m in \u001b[0;36mremove_background\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_background\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_transparent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtransparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtransparent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-3dab1da789fc>\u001b[0m in \u001b[0;36mget_transparent_mask\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Perform GrabCut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrabCut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgdModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgdModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGC_INIT_WITH_MASK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Remove the out-of-focus parts using the binary mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/grabcut.cpp:386: error: (-215:Assertion failed) !bgdSamples.empty() && !fgdSamples.empty() in function 'initGMMs'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Define the path to the images\n",
        "path = \"/content/images/\"\n",
        "\n",
        "for file in os.listdir(path):\n",
        "  # Load the image\n",
        "  image = cv2.imread(os.path.join(path, file))\n",
        "\n",
        "  # Convert the image to grayscale\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # Perform Otsu thresholding\n",
        "  _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "  # Define the mask for the GrabCut algorithm\n",
        "  mask = np.zeros(image.shape[:2], np.uint8)\n",
        "  bgdModel = np.zeros((1, 65), np.float64)\n",
        "  fgdModel = np.zeros((1, 65), np.float64)\n",
        "\n",
        "  # Define the rectangle to be used as the foreground\n",
        "  x, y, w, h = cv2.boundingRect(thresh)\n",
        "  rect = (x, y, w, h)\n",
        "\n",
        "  # Perform the GrabCut algorithm\n",
        "  cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
        "\n",
        "  # Remove the out-of-focus parts using the binary mask\n",
        "  mask = np.where((mask == 2) | (mask == 0), 0, 1).astype(\"uint8\")\n",
        "  image = image * mask[:, :, np.newaxis]\n",
        "\n",
        "  # Convert the image to RGBA format and make the background transparent\n",
        "  transparent = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
        "  transparent[:, :, 3] = mask.astype(int) * 255\n",
        "\n",
        "  # Save the transparent image\n",
        "  cv2.imwrite(os.path.join(path, \"transparent_\" + file), transparent)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "mhRRAr3tuAZu",
        "outputId": "7214f5e6-f706-43de-c40e-75a175d35e8d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-8626a74a8023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Convert the image to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# Perform Otsu thresholding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    }
  ]
}