{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXA7Ox4MbZr7wJjuba3ooh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saktheeswaranswan/random-math-addition-data-for-rnn-generator/blob/main/shutup_pannuga.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6h70e0InU1xu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import librosa\n",
        "\n",
        "# Load audio file\n",
        "audio_file = '/content/hornc.wav'\n",
        "audio_data, sampling_rate = librosa.load(audio_file, sr=None)\n",
        "\n",
        "# Get time vector for audio\n",
        "duration = librosa.get_duration(audio_data, sr=sampling_rate)\n",
        "time = np.linspace(0, duration, len(audio_data))\n",
        "\n",
        "# Save waveform to CSV file\n",
        "with open('audio_waveform.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Time', 'Amplitude'])\n",
        "    for i in range(len(time)):\n",
        "        writer.writerow([time[i], audio_data[i]])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxdpkR9VWeTv",
        "outputId": "ffb84dd8-4bfb-43e5-9fdc-4a985b3096ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Convert MP3 file to WAV\n",
        "AudioSegment.from_mp3(\"/content/sample_data/dfhdfgh.mp3\").export(\"audio.wav\", format=\"wav\")\n",
        "\n",
        "# Read CSV file\n",
        "with open('/content/audio_waveform.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    # Skip header row if present\n",
        "    next(reader, None)\n",
        "    # Extract time and amplitude values from each row\n",
        "    time = []\n",
        "    amplitude = []\n",
        "    for row in reader:\n",
        "        time.append(float(row[0]))\n",
        "        amplitude.append(float(row[1]))\n",
        "\n",
        "# Calculate sampling rate and duration of audio\n",
        "sampling_rate, audio_data = wavfile.read('audio.wav')\n",
        "duration = len(audio_data) / sampling_rate\n",
        "\n",
        "# Create time vector for audio\n",
        "audio_time = np.linspace(0, duration, len(audio_data))\n",
        "\n",
        "# Interpolate waveform data to match audio sampling rate\n",
        "interpolated_amplitude = np.interp(audio_time, time, amplitude)\n",
        "\n",
        "# Invert waveform to create an \"anti-signal\"\n",
        "anti_signal = -1 * interpolated_amplitude\n",
        "\n",
        "# Shift anti-signal to align with audio\n",
        "delay_in_seconds = 1.0  # adjust as needed\n",
        "shifted_anti_signal = np.roll(anti_signal, int(sampling_rate * delay_in_seconds))\n",
        "\n",
        "# Silence audio by multiplying it with the shifted anti-signal\n",
        "silenced_audio = audio_data * shifted_anti_signal\n",
        "\n",
        "# Write silenced audio to new WAV file\n",
        "wavfile.write('silenced_audio.wav', sampling_rate, silenced_audio)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "ImUr6GbqVo-h",
        "outputId": "30a65e79-6953-4336-e6ef-bbe99614cb3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-17d4a73a14ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Silence audio by multiplying it with the shifted anti-signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0msilenced_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_data\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshifted_anti_signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Write silenced audio to new WAV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1196135,2) (1196135,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Convert MP3 file to WAV\n",
        "AudioSegment.from_mp3(\"/content/horn.wav\").export(\"audio.wav\", format=\"wav\")\n",
        "\n",
        "# Read CSV file\n",
        "with open('audio_waveform.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    # Skip header row if present\n",
        "    next(reader, None)\n",
        "    # Extract amplitude values from second column of each row\n",
        "    amplitude = []\n",
        "    for row in reader:\n",
        "        amplitude.append(float(row[1]))\n",
        "\n",
        "# Calculate sampling rate and duration of audio\n",
        "sampling_rate, audio_data = wavfile.read('audio.wav')\n",
        "duration = len(audio_data) / sampling_rate\n",
        "\n",
        "# Create time vector for audio\n",
        "audio_time = np.linspace(0, duration, len(audio_data))\n",
        "\n",
        "# Interpolate waveform data to match audio sampling rate\n",
        "interpolated_amplitude = np.interp(audio_time, audio_time, amplitude)\n",
        "\n",
        "# Invert waveform to create an \"anti-signal\"\n",
        "anti_signal = -1 * interpolated_amplitude\n",
        "\n",
        "# Shift anti-signal to align with audio\n",
        "delay_in_seconds = 1.0  # adjust as needed\n",
        "shifted_anti_signal = np.roll(anti_signal, int(sampling_rate * delay_in_seconds))\n",
        "\n",
        "# Silence audio by multiplying it with the shifted anti-signal\n",
        "silenced_audio = audio_data * shifted_anti_signal[:, np.newaxis]\n",
        "\n",
        "# Write silenced audio to new WAV file\n",
        "wavfile.write('silenced_audio.wav', sampling_rate, silenced_audio)\n"
      ],
      "metadata": {
        "id": "3k6TUL3zW7N6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Convert MP3 file to WAV\n",
        "AudioSegment.from_mp3(\"/content/hornc.wav\").export(\"audio.wav\", format=\"wav\")\n",
        "\n",
        "# Read CSV file\n",
        "with open('audio_waveform.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    # Skip header row if present\n",
        "    next(reader, None)\n",
        "    # Extract time and amplitude values from each row\n",
        "    time = []\n",
        "    amplitude = []\n",
        "    for row in reader:\n",
        "        time.append(float(row[0]))\n",
        "        amplitude.append(float(row[1]))\n",
        "\n",
        "# Calculate sampling rate and duration of audio\n",
        "sampling_rate, audio_data = wavfile.read('audio.wav')\n",
        "duration = len(audio_data) / sampling_rate\n",
        "\n",
        "# Create time vector for audio\n",
        "audio_time = np.linspace(0, duration, len(audio_data))\n",
        "\n",
        "# Interpolate waveform data to match audio sampling rate\n",
        "interpolated_amplitude = np.interp(audio_time, time, amplitude)\n",
        "\n",
        "# Create a zero amplitude waveform\n",
        "silence = np.zeros_like(interpolated_amplitude)\n",
        "\n",
        "# Shift silence waveform to align with audio\n",
        "delay_in_seconds = 1.0  # adjust as needed\n",
        "shifted_silence = np.roll(silence, int(sampling_rate * delay_in_seconds))\n",
        "\n",
        "# Silence audio by multiplying it with the shifted silence waveform\n",
        "silenced_audio = audio_data * shifted_silence[:, np.newaxis]\n",
        "\n",
        "# Write silenced audio to new WAV file\n",
        "wavfile.write('silenced_audio.wav', sampling_rate, silenced_audio)\n"
      ],
      "metadata": {
        "id": "J1r_2kYfY3PV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pyaudio\n",
        "import queue\n",
        "\n",
        "# Define constants\n",
        "CHUNK_SIZE = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "CHANNELS = 1\n",
        "RATE = 44100\n",
        "DELAY = 1.0\n",
        "\n",
        "# Initialize PyAudio\n",
        "p = pyaudio.PyAudio()\n",
        "\n",
        "# Open microphone stream\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                frames_per_buffer=CHUNK_SIZE)\n",
        "\n",
        "# Define a queue to store audio chunks\n",
        "queue = queue.Queue()\n",
        "\n",
        "# Start streaming audio\n",
        "def callback(in_data, frame_count, time_info, status):\n",
        "    queue.put(in_data)\n",
        "    return (None, pyaudio.paContinue)\n",
        "\n",
        "stream.start_stream()\n",
        "stream.set_callback(callback)\n",
        "\n",
        "# Read waveform data from file\n",
        "waveform_data = np.genfromtxt('audio_waveform.csv', delimiter=',', skip_header=1)\n",
        "\n",
        "# Interpolate waveform data to match audio sampling rate\n",
        "audio_time = np.linspace(0, CHUNK_SIZE/RATE, CHUNK_SIZE)\n",
        "interpolated_waveform = np.interp(audio_time, waveform_data[:,0], waveform_data[:,1])\n",
        "\n",
        "# Invert waveform to create an \"anti-signal\"\n",
        "anti_signal = -1 * interpolated_waveform\n",
        "\n",
        "# Shift anti-signal to align with audio\n",
        "delay_in_samples = int(RATE * DELAY)\n",
        "shifted_anti_signal = np.roll(anti_signal, delay_in_samples)\n",
        "\n",
        "# Apply silencing in real time\n",
        "while True:\n",
        "    # Get audio chunk from queue\n",
        "    audio_chunk = queue.get()\n",
        "    audio_data = np.frombuffer(audio_chunk, dtype=np.int16)\n",
        "\n",
        "    # Apply silence to audio\n",
        "    silenced_audio = audio_data * shifted_anti_signal[:len(audio_data)]\n",
        "\n",
        "    # Convert silenced audio back to bytes and write to output stream\n",
        "    stream.write(silenced_audio.tobytes())\n"
      ],
      "metadata": {
        "id": "pY8VydQobUAD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}